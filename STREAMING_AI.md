# ğŸŒŠ Streaming AI - Chain of Thoughts en Temps RÃ©el

## ğŸ¯ Objectif

Afficher le "chain of thoughts" de l'IA **en franÃ§ais** pendant que l'appel API Ã  ChatGPT se fait, au lieu d'attendre 10-15 secondes avec un Ã©cran figÃ©. Le workflow final (JSON) est gÃ©nÃ©rÃ© et appliquÃ© uniquement Ã  la fin, de maniÃ¨re transparente.

## âœ¨ FonctionnalitÃ©s ImplÃ©mentÃ©es

### ğŸ§  SÃ©paration Chain of Thoughts / Workflow JSON

**Concept clÃ© :**
- **Avant le dÃ©limiteur `---WORKFLOW_JSON---`** : L'IA parle en franÃ§ais, explique son raisonnement
- **AprÃ¨s le dÃ©limiteur** : Le JSON du workflow (masquÃ© dans l'affichage)

**Format de rÃ©ponse de l'IA :**
```
Bonjour ! Je comprends que tu veux crÃ©er un workflow de validation.

Voici ce que je vais faire :
1. CrÃ©er une action pour vÃ©rifier les donnÃ©es
2. Ajouter une condition pour valider
3. GÃ©rer les erreurs potentielles

---WORKFLOW_JSON---
{"title":"Validation de donnÃ©es","workflowText":"<workflow>...</workflow>","preferences":{...}}
```

**Ce que l'utilisateur voit :**
```
Bonjour ! Je comprends que tu veux crÃ©er un workflow de validation.

Voici ce que je vais faire :
1. CrÃ©er une action pour vÃ©rifier les donnÃ©es
2. Ajouter une condition pour valider
3. GÃ©rer les erreurs potentielles
```

### Backend (`backend/src/routes/ai.routes.ts`)

1. **Streaming OpenAI activÃ©**
   - Ajout du paramÃ¨tre `stream: true` dans l'appel Ã  l'API OpenAI
   - Les rÃ©ponses arrivent mot par mot au lieu d'un bloc unique
   - **PAS de `response_format: json_object`** pour permettre le texte libre

2. **Server-Sent Events (SSE)**
   - Le backend transforme le stream OpenAI en Ã©vÃ©nements SSE
   - Format : `text/event-stream`
   - Connexion maintenue ouverte pendant toute la durÃ©e du stream

3. **Types d'Ã©vÃ©nements envoyÃ©s**
   ```typescript
   // Chunk de texte reÃ§u (conversation + JSON potentiel)
   { type: 'chunk', content: 'mot ou phrase' }
   
   // Stream terminÃ© avec JSON extrait (ou null si conversation pure)
   { type: 'done', data: '{"title":"...","workflowText":"...","preferences":{...}}' }
   // OU
   { type: 'done', data: null }  // Si juste une conversation
   
   // Erreur survenue
   { type: 'error', error: 'message d\'erreur' }
   ```

4. **Extraction et validation du JSON Ã  la fin**
   - Le texte complet est accumulÃ© pendant le stream
   - Ã€ la fin, on cherche le dÃ©limiteur `---WORKFLOW_JSON---`
   - Si trouvÃ© : on extrait le JSON aprÃ¨s le dÃ©limiteur et on valide
   - Si pas trouvÃ© : c'est une conversation pure (pas de workflow)
   - Envoi d'un Ã©vÃ©nement `done` avec le JSON extrait (ou `null`)

### Frontend (`frontend/src/.../polygon-sidebar-designer-view.tsx`)

1. **Gestion des messages**
   - State `messages` pour stocker l'historique de conversation
   - Type `Message` avec `role`, `content`, `isStreaming`

2. **Lecture du stream**
   - Utilisation de `fetch()` avec `response.body.getReader()`
   - DÃ©codage progressif des chunks SSE
   - Mise Ã  jour du message en temps rÃ©el

3. **Nettoyage de l'affichage et Rendu Markdown**
   - DÃ©tection du dÃ©limiteur `---WORKFLOW_JSON---` dans le contenu
   - **Affichage uniquement du texte AVANT le dÃ©limiteur** (conversation)
   - Le JSON est masquÃ© de l'interface utilisateur
   - **Rendu markdown** avec `react-markdown` pour les messages assistant
   - Support complet : titres, listes, code, emphase, citations
   - Animation de curseur clignotant pendant le streaming

4. **Mise Ã  jour du workflow (si JSON prÃ©sent)**
   - Une fois le JSON complet reÃ§u (Ã©vÃ©nement `done`)
   - **SI** `data !== null` â†’ Parsing et mise Ã  jour du workflow
   - **SINON** â†’ Conversation pure, pas de mise Ã  jour
   - Gestion des erreurs avec rollback et logs

### UI/UX (`polygon-sidebar-designer-view.module.scss`)

1. **Styles des messages**
   - Messages utilisateur : fond violet clair, alignÃ©s Ã  droite
   - Messages assistant : fond gris clair, alignÃ©s Ã  gauche
   - IcÃ´nes distinctes (User vs Bot)

2. **Animations**
   - `fadeIn` : apparition douce des messages
   - `blink` : curseur clignotant pendant le streaming

3. **Responsive**
   - Texte avec `pre-wrap` pour prÃ©server les sauts de ligne
   - `word-wrap` pour Ã©viter les dÃ©bordements

## ğŸ”„ Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚
â”‚  (Textarea) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ User envoie "CrÃ©er un workflow..."
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  handleSendMessage  â”‚
â”‚  - CrÃ©e userMessage â”‚
â”‚  - CrÃ©e assistantMessage (vide, isStreaming: true)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /api/ai/chat
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (Hono)            â”‚
â”‚  - ReÃ§oit message          â”‚
â”‚  - Appelle OpenAI (stream: true)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Stream SSE
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI API                â”‚
â”‚  - GÃ©nÃ¨re JSON progressivement
â”‚  - Envoie chunks          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Chunks OpenAI
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (ReadableStream)  â”‚
â”‚  - ReÃ§oit chunks OpenAI    â”‚
â”‚  - Transforme en SSE       â”‚
â”‚  - Envoie { type: 'chunk', content: '...' }
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ SSE Events
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Reader)         â”‚
â”‚  - Lit Ã©vÃ©nements SSE      â”‚
â”‚  - Accumule contenu        â”‚
â”‚  - Met Ã  jour UI en temps rÃ©el
â”‚  - Affiche "chain of thoughts" âš¡
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Stream terminÃ©
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend                   â”‚
â”‚  - Valide JSON complet     â”‚
â”‚  - Envoie { type: 'done', data: JSON }
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ JSON complet
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend                  â”‚
â”‚  - Parse JSON              â”‚
â”‚  - Met Ã  jour workflow     â”‚
â”‚  - DÃ©sactive isStreaming   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¨ ExpÃ©rience Utilisateur

### Avant (sans streaming)
```
User: "CrÃ©er un workflow de validation"
        â†“
[Spinner pendant 10-15 secondes] â³
        â†“
âœ… Workflow crÃ©Ã© !
```

### AprÃ¨s (avec streaming et chain of thoughts) â­

#### Cas 1 : CrÃ©ation de workflow
```
User: "CrÃ©er un workflow de validation"
        â†“
Bot: "Parfait ! Je comprends que..."  [< 1 seconde] âš¡
Bot: "Parfait ! Je comprends que tu veux crÃ©er..."  [streaming...]
Bot: "Parfait ! Je comprends que tu veux crÃ©er un workflow..."  [streaming...]
Bot: [texte complet en franÃ§ais visible]
        â†“
âœ… Workflow crÃ©Ã© automatiquement en arriÃ¨re-plan !
```

**Ce que l'utilisateur voit :**
```
Bot ğŸ¤–
Parfait ! Je comprends que tu veux crÃ©er un workflow de validation.

Voici ce que je vais mettre en place :
1. Une action pour vÃ©rifier les donnÃ©es entrantes
2. Une condition pour valider la conformitÃ©
3. Une gestion des erreurs avec notifications

Le workflow est maintenant crÃ©Ã© et prÃªt Ã  Ãªtre personnalisÃ© ! ğŸ‰
```

#### Cas 2 : Conversation pure (sans workflow)
```
User: "C'est quoi une action dbRead ?"
        â†“
Bot: "Bonne question !"  [< 1 seconde]
Bot: "Bonne question ! Une action dbRead..."  [streaming...]
Bot: [explication complÃ¨te]
        â†“
ğŸ’¬ Conversation uniquement (pas de workflow crÃ©Ã©)
```

**Ce que l'utilisateur voit :**
```
Bot ğŸ¤–
Bonne question ! Une action dbRead permet de lire des donnÃ©es depuis une base de donnÃ©es.

Elle est utile pour :
- RÃ©cupÃ©rer des informations stockÃ©es
- Effectuer des requÃªtes SQL
- Charger des configurations

Tu veux que je crÃ©e un exemple de workflow avec dbRead ?
```

## ğŸ”§ Points Techniques Importants

### 1. DÃ©limiteur de SÃ©paration Conversation/JSON

**ProblÃ¨me** : Comment afficher du texte conversationnel ET gÃ©nÃ©rer un JSON workflow ?

**Solution - DÃ©limiteur `---WORKFLOW_JSON---` :**

```typescript
// Backend : Extraction du JSON
const delimiter = '---WORKFLOW_JSON---';
const delimiterIndex = accumulatedText.indexOf(delimiter);

if (delimiterIndex !== -1) {
    const jsonPart = accumulatedText.substring(delimiterIndex + delimiter.length).trim();
    const parsedWorkflow = JSON.parse(jsonPart);
    // Envoyer le JSON au frontend
}
```

```typescript
// Frontend : Nettoyage de l'affichage
const delimiter = '---WORKFLOW_JSON---';
let displayContent = accumulatedContent;

const delimiterIndex = displayContent.indexOf(delimiter);
if (delimiterIndex !== -1) {
    // Afficher UNIQUEMENT le texte avant le dÃ©limiteur
    displayContent = displayContent.substring(0, delimiterIndex).trim();
}
```

### 2. Pas de `response_format: json_object`

**Important** : On n'utilise PLUS `response_format: { type: "json_object" }` car :
- Ã‡a forcerait l'IA Ã  retourner UNIQUEMENT du JSON
- On veut du texte libre + JSON optionnel
- Le dÃ©limiteur permet de sÃ©parer les deux

### 3. Gestion des Erreurs avec Try-Catch

**Types d'erreurs gÃ©rÃ©es** :
- Erreur rÃ©seau (fetch failed)
- Erreur OpenAI (API key invalide, quota dÃ©passÃ©)
- Erreur parsing JSON (rÃ©ponse malformÃ©e, clÃ©s manquantes)
- Interruption du stream
- DÃ©limiteur absent mais JSON attendu

**Try-catch cÃ´tÃ© Backend :**
```typescript
try {
    const jsonPart = accumulatedText.substring(delimiterIndex + delimiter.length).trim();
    const parsedWorkflow = JSON.parse(jsonPart);
    
    if (!parsedWorkflow.title || !parsedWorkflow.workflowText || !parsedWorkflow.preferences) {
        // Erreur : clÃ©s manquantes
    }
} catch (parseError) {
    controller.enqueue(new TextEncoder().encode(`data: ${JSON.stringify({ 
        type: 'error', 
        error: 'Erreur parsing workflow'
    })}\n\n`));
}
```

**Try-catch cÃ´tÃ© Frontend :**
```typescript
try {
    const parsedData = JSON.parse(fullJsonResponse);
    const { title, workflowText, preferences } = parsedData;
    // Mise Ã  jour du workflow...
} catch (parseError) {
    console.error('Erreur parsing workflow JSON:', parseError);
}

// Gestion globale
catch (error) {
    setMessages(prev => 
        prev.map(msg => 
            msg.id === assistantMessageId 
                ? { ...msg, content: `âŒ Erreur: ...`, isStreaming: false }
                : msg
        )
    );
}
```

### 4. Performance et Optimisations

- **Pas de re-render inutile** : on met Ã  jour uniquement le message concernÃ© avec `.map()`
- **Auto-scroll dÃ©sactivÃ©** (commentÃ©) pour Ã©viter les sauts lors du streaming
- **DÃ©codage progressif** avec `TextDecoder({ stream: true })`
- **Nettoyage du contenu Ã  chaque chunk** : le dÃ©limiteur et JSON sont retirÃ©s en temps rÃ©el
- **Double validation** : cÃ´tÃ© backend ET frontend pour garantir l'intÃ©gritÃ©

## ğŸš€ Comment Tester

1. **DÃ©marrer le backend**
   ```bash
   cd backend
   bun run dev
   ```

2. **DÃ©marrer le frontend**
   ```bash
   cd frontend
   bun run dev
   ```

3. **Ouvrir l'app et aller dans un workflow**

4. **Cliquer sur l'icÃ´ne AI (Bot) dans la sidebar**

5. **Taper un message et observer le streaming** ğŸŒŠ

   **Exemples de demandes qui crÃ©ent un workflow :**
   - "CrÃ©er un workflow de validation de formulaire"
   - "Je veux automatiser l'envoi d'emails de bienvenue"
   - "Construis-moi un workflow de traitement de commandes"
   
   **Exemples de conversations pures (sans workflow) :**
   - "C'est quoi une action dbRead ?"
   - "Explique-moi comment fonctionnent les conditions"
   - "Quelles sont les bonnes pratiques ?"
   
   **Observer :**
   - Le texte en franÃ§ais apparaÃ®t progressivement âš¡
   - Le curseur clignote pendant le streaming â–Š
   - Le JSON n'est JAMAIS visible dans le chat
   - Le workflow est crÃ©Ã© automatiquement en arriÃ¨re-plan (si applicable)

## ğŸ“ Support Markdown âœ…

### ImplÃ©mentÃ© avec `react-markdown`

L'IA peut maintenant utiliser du markdown pour formater ses rÃ©ponses :

**FonctionnalitÃ©s supportÃ©es :**
- âœ… **Titres** : `# H1`, `## H2`, `### H3`
- âœ… **Emphase** : `**gras**`, `*italique*`
- âœ… **Listes** : NumÃ©rotÃ©es et Ã  puces (avec sous-listes)
- âœ… **Code** : `` `inline` `` et blocs de code avec ```
- âœ… **Citations** : `> Blockquote`
- âœ… **GitHub Flavored Markdown** : Tables, task lists, etc.

**Exemple de rÃ©ponse markdown :**
```markdown
## ğŸ¯ Voici ce que je vais crÃ©er :

1. **Action de validation**
   - VÃ©rification des champs requis
   - Format email avec `regex`

2. **Sauvegarde des donnÃ©es**
   - Utilisation de `dbCreate`
   - Transaction sÃ©curisÃ©e

> ğŸ’¡ **Astuce** : Tu peux personnaliser ces rÃ¨gles !

Le workflow est crÃ©Ã© ! ğŸ‰
```

**Voir** : `MARKDOWN_SUPPORT.md` pour la documentation complÃ¨te

## ğŸ“ AmÃ©liorations Futures Possibles

1. ~~**Markdown Rendering**~~ âœ… **Fait !**
   - âœ… Parser le markdown dans les rÃ©ponses (gras, listes, code blocks)

2. **Code Syntax Highlighting**
   - Si l'IA envoie du code XML/JSON, le colorer

3. **Stop Button**
   - Permettre d'annuler le stream en cours
   - Utiliser `AbortController`

4. **Historique Persistant**
   - Sauvegarder les conversations dans localStorage
   - Reprendre la conversation oÃ¹ on l'a laissÃ©e

5. **Multi-turn Conversation**
   - Envoyer l'historique complet Ã  l'IA
   - Context awareness pour les questions de suivi

6. **Retry Mechanism**
   - Bouton "RÃ©essayer" en cas d'erreur
   - Reconnexion automatique si le stream Ã©choue

## âš ï¸ Notes Importantes

- L'API OpenAI doit supporter le streaming (gpt-4o-mini âœ…)
- Le format `response_format: { type: "json_object" }` fonctionne avec le streaming
- Les CORS doivent Ãªtre correctement configurÃ©s sur le backend
- Le streaming consomme autant de tokens qu'une rÃ©ponse classique

## ğŸ‰ RÃ©sultat Final

### âœ… Avantages de cette Approche

1. **Conversation Naturelle** ğŸ’¬
   - L'IA parle en franÃ§ais, comme un assistant humain
   - Explications claires et pÃ©dagogiques
   - Peut poser des questions de clarification

2. **Feedback InstantanÃ©** âš¡
   - Texte visible en < 1 seconde
   - Pas d'attente dans le vide
   - L'utilisateur sait que Ã§a marche

3. **Transparence du Raisonnement** ğŸ§ 
   - Chain of thoughts visible en temps rÃ©el
   - L'utilisateur comprend ce que l'IA fait
   - CrÃ©ation de confiance

4. **Workflow Automatique** ğŸ¯
   - Le JSON est gÃ©nÃ©rÃ© et appliquÃ© en arriÃ¨re-plan
   - L'utilisateur n'a pas besoin de voir le code technique
   - ExpÃ©rience fluide et professionnelle

5. **FlexibilitÃ©** ğŸ”„
   - Peut rÃ©pondre Ã  des questions sans crÃ©er de workflow
   - Peut crÃ©er/modifier des workflows quand nÃ©cessaire
   - S'adapte au contexte de la conversation

### ğŸš€ ExpÃ©rience Utilisateur TransformÃ©e

**Avant :**
```
User: "CrÃ©er un workflow"
[Ã‰cran figÃ© 15 secondes]
âœ… Fait
```

**Maintenant :**
```
User: "CrÃ©er un workflow"

Bot: "Parfait ! Je comprends..." [instantanÃ©]
Bot: "Je vais crÃ©er..." [streaming visible]
Bot: "Voici les Ã©tapes..." [explication complÃ¨te]

âœ… Workflow crÃ©Ã© automatiquement !
```

L'utilisateur voit maintenant le "raisonnement" de l'IA se construire en temps rÃ©el **en franÃ§ais**, crÃ©ant une expÃ©rience beaucoup plus engageante, transparente et professionnelle ! ğŸš€

